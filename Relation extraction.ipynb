{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9aebe078",
   "metadata": {},
   "source": [
    "# Relation extraction\n",
    "## Table of contents<a name=contents></a>\n",
    "1. [Packages](#packages)\n",
    "2. [Text](#text)\n",
    "3. [NLP pipes](#pipes)\n",
    "4. [Dependency trees](#trees)\n",
    "\n",
    "## 1. Packages <a name=packages></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "7c5cc1bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy import displacy\n",
    "\n",
    "\n",
    "from spacy.tokens import Token\n",
    "from spacy import Language\n",
    "\n",
    "from collections import deque\n",
    "\n",
    "from nltk.corpus import reuters\n",
    "\n",
    "import regex as re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fbd8d3f",
   "metadata": {},
   "source": [
    "## 2. Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b62c8b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_lg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "57cfc2b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Fujitsu, a competitor of NEC, acquired Fairchild Corp.\"\n",
    "doc = nlp(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "71e183c7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"6c42b252a709493db587ce4feda33a9f-0\" class=\"displacy\" width=\"850\" height=\"287.0\" direction=\"ltr\" style=\"max-width: none; height: 287.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"197.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">Fujitsu,</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"197.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"150\">a</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"150\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"197.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"250\">competitor</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"250\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"197.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"350\">of</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"350\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"197.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"450\">NEC,</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"450\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"197.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"550\">acquired</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"550\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"197.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"650\">Fairchild</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"650\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"197.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">Corp.</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-6c42b252a709493db587ce4feda33a9f-0-0\" stroke-width=\"2px\" d=\"M70,152.0 C70,2.0 550.0,2.0 550.0,152.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-6c42b252a709493db587ce4feda33a9f-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,154.0 L62,142.0 78,142.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-6c42b252a709493db587ce4feda33a9f-0-1\" stroke-width=\"2px\" d=\"M170,152.0 C170,102.0 240.0,102.0 240.0,152.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-6c42b252a709493db587ce4feda33a9f-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M170,154.0 L162,142.0 178,142.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-6c42b252a709493db587ce4feda33a9f-0-2\" stroke-width=\"2px\" d=\"M70,152.0 C70,52.0 245.0,52.0 245.0,152.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-6c42b252a709493db587ce4feda33a9f-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">appos</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M245.0,154.0 L253.0,142.0 237.0,142.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-6c42b252a709493db587ce4feda33a9f-0-3\" stroke-width=\"2px\" d=\"M270,152.0 C270,102.0 340.0,102.0 340.0,152.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-6c42b252a709493db587ce4feda33a9f-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M340.0,154.0 L348.0,142.0 332.0,142.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-6c42b252a709493db587ce4feda33a9f-0-4\" stroke-width=\"2px\" d=\"M370,152.0 C370,102.0 440.0,102.0 440.0,152.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-6c42b252a709493db587ce4feda33a9f-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M440.0,154.0 L448.0,142.0 432.0,142.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-6c42b252a709493db587ce4feda33a9f-0-5\" stroke-width=\"2px\" d=\"M670,152.0 C670,102.0 740.0,102.0 740.0,152.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-6c42b252a709493db587ce4feda33a9f-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M670,154.0 L662,142.0 678,142.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-6c42b252a709493db587ce4feda33a9f-0-6\" stroke-width=\"2px\" d=\"M570,152.0 C570,52.0 745.0,52.0 745.0,152.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-6c42b252a709493db587ce4feda33a9f-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M745.0,154.0 L753.0,142.0 737.0,142.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "displacy.render(doc, style=\"dep\",options={'compact': False, 'distance': 100})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d6ffed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "02b7035a",
   "metadata": {},
   "source": [
    "Back to the [table of contents](#contents).\n",
    "\n",
    "## 3. NLP pipes <a name=pipes></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e7c3f160",
   "metadata": {},
   "outputs": [],
   "source": [
    "Token.set_extension('ref_n', default='', force = True)\n",
    "Token.set_extension('ref_t', default='', force = True)\n",
    "\n",
    "@Language.component(\"init_coref\")\n",
    "def init_coref(doc):\n",
    "    for e in doc.ents:\n",
    "        if e.label_ in ['ORG', 'GOV', 'PERSON']:\n",
    "            e[0]._.ref_n, e[0]._.ref_t = e.text, e.label_\n",
    "    return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a4981534",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: core_web_lg, Language: en\n",
      "('tok2vec', <spacy.pipeline.tok2vec.Tok2Vec object at 0x7f13c8420f30>)\n",
      "('tagger', <spacy.pipeline.tagger.Tagger object at 0x7f13c8420ec0>)\n",
      "('parser', <spacy.pipeline.dep_parser.DependencyParser object at 0x7f13c815cc50>)\n",
      "('attribute_ruler', <spacy.pipeline.attributeruler.AttributeRuler object at 0x7f13c81885f0>)\n",
      "('lemmatizer', <spacy.lang.en.lemmatizer.EnglishLemmatizer object at 0x7f13c81722d0>)\n",
      "('ner', <spacy.pipeline.ner.EntityRecognizer object at 0x7f13c815ce50>)\n",
      "('init_coref', <function init_coref at 0x7f13c17cd4d0>)\n"
     ]
    }
   ],
   "source": [
    "def reset_pipeline(nlp, pipes):\n",
    "    # remove all custom pipes\n",
    "    custom_pipes = [pipe for (pipe, _) in nlp.pipeline\n",
    "                    if pipe not in ['tagger', 'parser', 'ner',\n",
    "                                    'tok2vec', 'attribute_ruler', 'lemmatizer']]\n",
    "    for pipe in custom_pipes:\n",
    "        _ = nlp.remove_pipe(pipe)\n",
    "    # re-add specified pipes\n",
    "    for pipe in pipes:\n",
    "        if 'neuralcoref' == pipe or 'neuralcoref' in str(pipe.__class__):\n",
    "            nlp.add_pipe(pipe, name='neural_coref')\n",
    "        else:\n",
    "            nlp.add_pipe(pipe)\n",
    "\n",
    "    print(f\"Model: {nlp.meta['name']}, Language: {nlp.meta['lang']}\")\n",
    "    print(*nlp.pipeline, sep='\\n')\n",
    "    \n",
    "reset_pipeline(nlp, ['init_coref'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ee2304",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7c74f813",
   "metadata": {},
   "source": [
    "Back to the [table of contents](#contents).\n",
    "\n",
    "## 4. Dependency trees <a name=trees></a>\n",
    "\n",
    "Dependency trees seem to be very efficient to find verbs (active or passive) and their subject and object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "98f7527b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Actually we search for the shortest path between the\n",
    "# subject running through our predicate (verb) to the object.\n",
    "# subject and object are organizations in our examples.\n",
    "\n",
    "# Here are the three helper functions omitted in the book:\n",
    "# - bfs: breadth first searching the closest subject/object \n",
    "# - is_passive: checks if noun or verb is in passive form\n",
    "# - find_subj: searches left part of tree for subject\n",
    "# - find_obj: searches right part of tree for object\n",
    "\n",
    "def bfs(root, ent_type: str, deps:list, first_dep_only=False):\n",
    "    \"\"\"\n",
    "    \n",
    "    : root: token containing the word at the left of the verb, hopefully the subject?\n",
    "    : ent_type: specifies entity type (for now always called for \"ORG\")\n",
    "    : deps: ??? ['nsubjpass', 'nsubj:pass'] ???\n",
    "    : first_dep_only: \n",
    "    \"\"\"\n",
    "    \"\"\"Return first child of root (included) that matches\n",
    "    ent_type and dependency list by breadth first search.\n",
    "    Search stops after first dependency match if first_dep_only\n",
    "    (used for subject search - do not \"jump\" over subjects)\"\"\"\n",
    "    # deque to ease the access to the list\n",
    "    to_visit = deque([root]) # queue for bfs\n",
    "\n",
    "    while len(to_visit) > 0:\n",
    "        # the left element of the queue is given to child and deleted from the queue\n",
    "        child = to_visit.popleft()\n",
    "        # print(\"child\", child, child.dep_)\n",
    "        # check if the dependency of the token was one of those provided\n",
    "        if child.dep_ in deps:\n",
    "            # check if the label/entity type is the same as the one provided\n",
    "            if child._.ref_t == ent_type:\n",
    "                return child\n",
    "            # explore what to do if we keep looking after the first dependency match?\n",
    "            # quid for a subject with an \"and\"???\n",
    "            elif first_dep_only: # first match (subjects)\n",
    "                return None\n",
    "        # check if it is a compound (adjective),\n",
    "        # if the noun it describes dependency is one of those provided\n",
    "        # and if it has the right entity type but only works on the first token of the entity (customized pipe)\n",
    "        # why doesn't it return the whole entity then? A compound is no subject by its own...?\n",
    "        elif child.dep_ == 'compound' and \\\n",
    "             child.head.dep_ in deps and \\\n",
    "             child._.ref_t == ent_type: # check if contained in compound\n",
    "            return child\n",
    "        to_visit.extend(list(child.children))\n",
    "    return None\n",
    "\n",
    "def is_passive(token):\n",
    "    if token.dep_.endswith('pass'): # noun\n",
    "        return True\n",
    "    for left in token.lefts: # verb\n",
    "        if left.dep_ == 'auxpass':\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def find_subj(pred, ent_type: str, passive: bool):\n",
    "    \"\"\"\n",
    "    Find closest subject in predicates left subtree or\n",
    "    predicates parent's left subtree (recursive).\n",
    "    Has a filter on organizations.\n",
    "    : pred: token containing a verb\n",
    "    : ent_type: specifies entity type (for now always called for \"ORG\")\n",
    "    : passive: specifies if the verb is in the passive form\n",
    "    : return: pred's subject\n",
    "    \"\"\"\n",
    "    ## To modify to make it work for different kind of entities\n",
    "\n",
    "    # begins with the further related word on the left of the predicate\n",
    "    for left in pred.lefts:\n",
    "        if passive: # if pred is passive, search for passive subject\n",
    "            subj = bfs(left, ent_type, ['nsubjpass', 'nsubj:pass'], True)\n",
    "        else:\n",
    "            subj = bfs(left, ent_type, ['nsubj'], True)\n",
    "        if subj is not None: # found it!\n",
    "            return subj\n",
    "    \n",
    "    # if the subject is not on the left tree of the predicate,\n",
    "    # the predicate's head could be another verb with the same subject\n",
    "    # example: Apple is looking at buying a startup\n",
    "    if pred.head != pred and not is_passive(pred): # why not just \"passive\" instead of is_passive(pred)?\n",
    "        return find_subj(pred.head, ent_type, passive) # climb up left subtree\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def find_obj(pred, ent_type, excl_prepos):\n",
    "    \"\"\"\n",
    "    Find closest object in predicates right subtree.\n",
    "    Skip prepositional objects if the preposition is in exclude list.\n",
    "    Has a filter on organizations.\n",
    "    : pred: token containing a verb\n",
    "    : ent_type: specifies entity type (for now always called for \"ORG\")\n",
    "    : excl_prepos: excluded prepositions\n",
    "    : return: object of the predicate\n",
    "    \"\"\"\n",
    "    \n",
    "    ## To modify to make it work for different kind of entities\n",
    "        \n",
    "    # looks into every related token on the right of the predicate\n",
    "    # until it finds an object filling the conditions\n",
    "    for right in pred.rights:\n",
    "        print(\"right: \",right)\n",
    "        obj = bfs(right, ent_type, ['dobj', 'pobj', 'iobj', 'obj', 'obl'])\n",
    "        # if an object is found,\n",
    "        # it looks that its preposition is not excluded\n",
    "        if obj is not None:\n",
    "            if obj.dep_ == 'pobj' and obj.head.lemma_.lower() in excl_prepos: # check preposition\n",
    "                continue\n",
    "            return obj\n",
    "    return None\n",
    "\n",
    "def extract_rel_dep(doc, pred_name:str, pred_synonyms:str, excl_prepos=[]):\n",
    "    \"\"\"\n",
    "    Method extracting relationship(s) (may be plural!)\n",
    "    It only returns triplets!\n",
    "    : doc: text to analyze\n",
    "    : pred_name: predicate\n",
    "    : pred_synonyms: predicate's synonyms\n",
    "    : excl_prepos: prepositions which can not precede the object chosen\n",
    "    : return: triplet(s) with the subject and its entity type,\n",
    "              the predicate and the object and its entity type\n",
    "    \"\"\"\n",
    "    for token in doc:\n",
    "        #print(token, token.pos_, token.lemma_)\n",
    "        # looks for a verb equivalent to the predicate referred to\n",
    "        if token.pos_ == 'VERB' and token.lemma_ in pred_synonyms:\n",
    "            print(\"found token: \",token)\n",
    "            # saves that verb as a predicate (readability)\n",
    "            # looks if it is passive\n",
    "            # and then searches for the subject of the verb\n",
    "            pred = token\n",
    "            passive = is_passive(pred)\n",
    "            print(\"passive: \",passive)\n",
    "            subj = find_subj(pred, 'ORG', passive)\n",
    "            print(\"subject: \",subj)\n",
    "            # if the subject is found, it looks for the object\n",
    "            if subj is not None:\n",
    "                obj = find_obj(pred, 'ORG', excl_prepos)\n",
    "                print(\"object: \",obj)\n",
    "                if obj is not None:\n",
    "                    # if there is a subject and an object,\n",
    "                    # it sets the triplet in the following order:\n",
    "                    # active subject, verb in active form, passive subject\n",
    "                    if passive: # switch roles\n",
    "                        obj, subj = subj, obj\n",
    "                    yield ((subj._.ref_n, subj._.ref_t), pred_name, \n",
    "                           (obj._.ref_n, obj._.ref_t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bcd0743a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'spacy.tokens.token.Token'> VERB VBZ\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"sells\")\n",
    "for token in doc:\n",
    "    print(type(token),token.pos_,token.tag_)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5358d514",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class Token in module spacy.tokens.token:\n",
      "\n",
      "class Token(builtins.object)\n",
      " |  An individual token – i.e. a word, punctuation symbol, whitespace,\n",
      " |  etc.\n",
      " |  \n",
      " |  DOCS: https://spacy.io/api/token\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __bytes__(...)\n",
      " |      Token.__bytes__(self)\n",
      " |  \n",
      " |  __eq__(self, value, /)\n",
      " |      Return self==value.\n",
      " |  \n",
      " |  __ge__(self, value, /)\n",
      " |      Return self>=value.\n",
      " |  \n",
      " |  __gt__(self, value, /)\n",
      " |      Return self>value.\n",
      " |  \n",
      " |  __hash__(self, /)\n",
      " |      Return hash(self).\n",
      " |  \n",
      " |  __le__(self, value, /)\n",
      " |      Return self<=value.\n",
      " |  \n",
      " |  __len__(...)\n",
      " |      The number of unicode characters in the token, i.e. `token.text`.\n",
      " |      \n",
      " |      RETURNS (int): The number of unicode characters in the token.\n",
      " |      \n",
      " |      DOCS: https://spacy.io/api/token#len\n",
      " |  \n",
      " |  __lt__(self, value, /)\n",
      " |      Return self<value.\n",
      " |  \n",
      " |  __ne__(self, value, /)\n",
      " |      Return self!=value.\n",
      " |  \n",
      " |  __reduce__(...)\n",
      " |      Token.__reduce__(self)\n",
      " |  \n",
      " |  __repr__(self, /)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __str__(self, /)\n",
      " |      Return str(self).\n",
      " |  \n",
      " |  __unicode__(...)\n",
      " |      Token.__unicode__(self)\n",
      " |  \n",
      " |  check_flag(...)\n",
      " |      Token.check_flag(self, attr_id_t flag_id) -> bool\n",
      " |      Check the value of a boolean flag.\n",
      " |      \n",
      " |              flag_id (int): The ID of the flag attribute.\n",
      " |              RETURNS (bool): Whether the flag is set.\n",
      " |      \n",
      " |              DOCS: https://spacy.io/api/token#check_flag\n",
      " |  \n",
      " |  has_dep(...)\n",
      " |      Token.has_dep(self)\n",
      " |      Check whether the token has annotated dep information.\n",
      " |              Returns False when the dep label is unset/missing.\n",
      " |      \n",
      " |              RETURNS (bool): Whether the dep label is valid or not.\n",
      " |  \n",
      " |  has_head(...)\n",
      " |      Token.has_head(self)\n",
      " |      Check whether the token has annotated head information.\n",
      " |              Return False when the head annotation is unset/missing.\n",
      " |      \n",
      " |              RETURNS (bool): Whether the head annotation is valid or not.\n",
      " |  \n",
      " |  has_morph(...)\n",
      " |      Token.has_morph(self)\n",
      " |      Check whether the token has annotated morph information.\n",
      " |              Return False when the morph annotation is unset/missing.\n",
      " |      \n",
      " |              RETURNS (bool): Whether the morph annotation is set.\n",
      " |  \n",
      " |  is_ancestor(...)\n",
      " |      Token.is_ancestor(self, descendant)\n",
      " |      Check whether this token is a parent, grandparent, etc. of another\n",
      " |              in the dependency tree.\n",
      " |      \n",
      " |              descendant (Token): Another token.\n",
      " |              RETURNS (bool): Whether this token is the ancestor of the descendant.\n",
      " |      \n",
      " |              DOCS: https://spacy.io/api/token#is_ancestor\n",
      " |  \n",
      " |  nbor(...)\n",
      " |      Token.nbor(self, int i=1)\n",
      " |      Get a neighboring token.\n",
      " |      \n",
      " |              i (int): The relative position of the token to get. Defaults to 1.\n",
      " |              RETURNS (Token): The token at position `self.doc[self.i+i]`.\n",
      " |      \n",
      " |              DOCS: https://spacy.io/api/token#nbor\n",
      " |  \n",
      " |  set_morph(...)\n",
      " |      Token.set_morph(self, features)\n",
      " |  \n",
      " |  similarity(...)\n",
      " |      Token.similarity(self, other)\n",
      " |      Make a semantic similarity estimate. The default estimate is cosine\n",
      " |              similarity using an average of word vectors.\n",
      " |      \n",
      " |              other (object): The object to compare with. By default, accepts `Doc`,\n",
      " |                  `Span`, `Token` and `Lexeme` objects.\n",
      " |              RETURNS (float): A scalar similarity score. Higher is more similar.\n",
      " |      \n",
      " |              DOCS: https://spacy.io/api/token#similarity\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods defined here:\n",
      " |  \n",
      " |  get_extension(...) from builtins.type\n",
      " |      Token.get_extension(type cls, name)\n",
      " |      Look up a previously registered extension by name.\n",
      " |      \n",
      " |              name (str): Name of the extension.\n",
      " |              RETURNS (tuple): A `(default, method, getter, setter)` tuple.\n",
      " |      \n",
      " |              DOCS: https://spacy.io/api/token#get_extension\n",
      " |  \n",
      " |  has_extension(...) from builtins.type\n",
      " |      Token.has_extension(type cls, name)\n",
      " |      Check whether an extension has been registered.\n",
      " |      \n",
      " |              name (str): Name of the extension.\n",
      " |              RETURNS (bool): Whether the extension has been registered.\n",
      " |      \n",
      " |              DOCS: https://spacy.io/api/token#has_extension\n",
      " |  \n",
      " |  iob_strings(...) from builtins.type\n",
      " |      Token.iob_strings(type cls)\n",
      " |  \n",
      " |  remove_extension(...) from builtins.type\n",
      " |      Token.remove_extension(type cls, name)\n",
      " |      Remove a previously registered extension.\n",
      " |      \n",
      " |              name (str): Name of the extension.\n",
      " |              RETURNS (tuple): A `(default, method, getter, setter)` tuple of the\n",
      " |                  removed extension.\n",
      " |      \n",
      " |              DOCS: https://spacy.io/api/token#remove_extension\n",
      " |  \n",
      " |  set_extension(...) from builtins.type\n",
      " |      Token.set_extension(type cls, name, **kwargs)\n",
      " |      Define a custom attribute which becomes available as `Token._`.\n",
      " |      \n",
      " |              name (str): Name of the attribute to set.\n",
      " |              default: Optional default value of the attribute.\n",
      " |              getter (callable): Optional getter function.\n",
      " |              setter (callable): Optional setter function.\n",
      " |              method (callable): Optional method for method extension.\n",
      " |              force (bool): Force overwriting existing attribute.\n",
      " |      \n",
      " |              DOCS: https://spacy.io/api/token#set_extension\n",
      " |              USAGE: https://spacy.io/usage/processing-pipelines#custom-components-attributes\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Static methods defined here:\n",
      " |  \n",
      " |  __new__(*args, **kwargs) from builtins.type\n",
      " |      Create and return a new object.  See help(type) for accurate signature.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  ancestors\n",
      " |      A sequence of this token's syntactic ancestors.\n",
      " |      \n",
      " |      YIELDS (Token): A sequence of ancestor tokens such that\n",
      " |          `ancestor.is_ancestor(self)`.\n",
      " |      \n",
      " |      DOCS: https://spacy.io/api/token#ancestors\n",
      " |  \n",
      " |  children\n",
      " |      A sequence of the token's immediate syntactic children.\n",
      " |      \n",
      " |      YIELDS (Token): A child token such that `child.head==self`.\n",
      " |      \n",
      " |      DOCS: https://spacy.io/api/token#children\n",
      " |  \n",
      " |  cluster\n",
      " |      RETURNS (int): Brown cluster ID.\n",
      " |  \n",
      " |  conjuncts\n",
      " |      A sequence of coordinated tokens, including the token itself.\n",
      " |      \n",
      " |      RETURNS (tuple): The coordinated tokens.\n",
      " |      \n",
      " |      DOCS: https://spacy.io/api/token#conjuncts\n",
      " |  \n",
      " |  dep\n",
      " |      RETURNS (uint64): ID of syntactic dependency label.\n",
      " |  \n",
      " |  dep_\n",
      " |      RETURNS (str): The syntactic dependency label.\n",
      " |  \n",
      " |  doc\n",
      " |  \n",
      " |  ent_id\n",
      " |      RETURNS (uint64): ID of the entity the token is an instance of,\n",
      " |      if any.\n",
      " |  \n",
      " |  ent_id_\n",
      " |      RETURNS (str): ID of the entity the token is an instance of,\n",
      " |      if any.\n",
      " |  \n",
      " |  ent_iob\n",
      " |      IOB code of named entity tag. `1=\"I\", 2=\"O\", 3=\"B\"`. 0 means no tag\n",
      " |      is assigned.\n",
      " |      \n",
      " |      RETURNS (uint64): IOB code of named entity tag.\n",
      " |  \n",
      " |  ent_iob_\n",
      " |      IOB code of named entity tag. \"B\" means the token begins an entity,\n",
      " |      \"I\" means it is inside an entity, \"O\" means it is outside an entity,\n",
      " |      and \"\" means no entity tag is set. \"B\" with an empty ent_type\n",
      " |      means that the token is blocked from further processing by NER.\n",
      " |      \n",
      " |      RETURNS (str): IOB code of named entity tag.\n",
      " |  \n",
      " |  ent_kb_id\n",
      " |      RETURNS (uint64): Named entity KB ID.\n",
      " |  \n",
      " |  ent_kb_id_\n",
      " |      RETURNS (str): Named entity KB ID.\n",
      " |  \n",
      " |  ent_type\n",
      " |      RETURNS (uint64): Named entity type.\n",
      " |  \n",
      " |  ent_type_\n",
      " |      RETURNS (str): Named entity type.\n",
      " |  \n",
      " |  has_vector\n",
      " |      A boolean value indicating whether a word vector is associated with\n",
      " |      the object.\n",
      " |      \n",
      " |      RETURNS (bool): Whether a word vector is associated with the object.\n",
      " |      \n",
      " |      DOCS: https://spacy.io/api/token#has_vector\n",
      " |  \n",
      " |  head\n",
      " |      The syntactic parent, or \"governor\", of this token.\n",
      " |      If token.has_head() is `False`, this method will return itself.\n",
      " |      \n",
      " |      RETURNS (Token): The token predicted by the parser to be the head of\n",
      " |          the current token.\n",
      " |  \n",
      " |  i\n",
      " |  \n",
      " |  idx\n",
      " |      RETURNS (int): The character offset of the token within the parent\n",
      " |      document.\n",
      " |  \n",
      " |  is_alpha\n",
      " |      RETURNS (bool): Whether the token consists of alpha characters.\n",
      " |      Equivalent to `token.text.isalpha()`.\n",
      " |  \n",
      " |  is_ascii\n",
      " |      RETURNS (bool): Whether the token consists of ASCII characters.\n",
      " |      Equivalent to `[any(ord(c) >= 128 for c in token.text)]`.\n",
      " |  \n",
      " |  is_bracket\n",
      " |      RETURNS (bool): Whether the token is a bracket.\n",
      " |  \n",
      " |  is_currency\n",
      " |      RETURNS (bool): Whether the token is a currency symbol.\n",
      " |  \n",
      " |  is_digit\n",
      " |      RETURNS (bool): Whether the token consists of digits. Equivalent to\n",
      " |      `token.text.isdigit()`.\n",
      " |  \n",
      " |  is_left_punct\n",
      " |      RETURNS (bool): Whether the token is a left punctuation mark.\n",
      " |  \n",
      " |  is_lower\n",
      " |      RETURNS (bool): Whether the token is in lowercase. Equivalent to\n",
      " |      `token.text.islower()`.\n",
      " |  \n",
      " |  is_oov\n",
      " |      RETURNS (bool): Whether the token is out-of-vocabulary.\n",
      " |  \n",
      " |  is_punct\n",
      " |      RETURNS (bool): Whether the token is punctuation.\n",
      " |  \n",
      " |  is_quote\n",
      " |      RETURNS (bool): Whether the token is a quotation mark.\n",
      " |  \n",
      " |  is_right_punct\n",
      " |      RETURNS (bool): Whether the token is a right punctuation mark.\n",
      " |  \n",
      " |  is_sent_end\n",
      " |      A boolean value indicating whether the token ends a sentence.\n",
      " |      `None` if unknown. Defaults to `True` for the last token in the `Doc`.\n",
      " |      \n",
      " |      RETURNS (bool / None): Whether the token ends a sentence.\n",
      " |          None if unknown.\n",
      " |      \n",
      " |      DOCS: https://spacy.io/api/token#is_sent_end\n",
      " |  \n",
      " |  is_sent_start\n",
      " |      A boolean value indicating whether the token starts a sentence.\n",
      " |      `None` if unknown. Defaults to `True` for the first token in the `Doc`.\n",
      " |      \n",
      " |      RETURNS (bool / None): Whether the token starts a sentence.\n",
      " |          None if unknown.\n",
      " |      \n",
      " |      DOCS: https://spacy.io/api/token#is_sent_start\n",
      " |  \n",
      " |  is_space\n",
      " |      RETURNS (bool): Whether the token consists of whitespace characters.\n",
      " |      Equivalent to `token.text.isspace()`.\n",
      " |  \n",
      " |  is_stop\n",
      " |      RETURNS (bool): Whether the token is a stop word, i.e. part of a\n",
      " |      \"stop list\" defined by the language data.\n",
      " |  \n",
      " |  is_title\n",
      " |      RETURNS (bool): Whether the token is in titlecase. Equivalent to\n",
      " |      `token.text.istitle()`.\n",
      " |  \n",
      " |  is_upper\n",
      " |      RETURNS (bool): Whether the token is in uppercase. Equivalent to\n",
      " |      `token.text.isupper()`\n",
      " |  \n",
      " |  lang\n",
      " |      RETURNS (uint64): ID of the language of the parent document's\n",
      " |      vocabulary.\n",
      " |  \n",
      " |  lang_\n",
      " |      RETURNS (str): Language of the parent document's vocabulary,\n",
      " |      e.g. 'en'.\n",
      " |  \n",
      " |  left_edge\n",
      " |      The leftmost token of this token's syntactic descendents.\n",
      " |      \n",
      " |      RETURNS (Token): The first token such that `self.is_ancestor(token)`.\n",
      " |  \n",
      " |  lefts\n",
      " |      The leftward immediate children of the word, in the syntactic\n",
      " |      dependency parse.\n",
      " |      \n",
      " |      YIELDS (Token): A left-child of the token.\n",
      " |      \n",
      " |      DOCS: https://spacy.io/api/token#lefts\n",
      " |  \n",
      " |  lemma\n",
      " |      RETURNS (uint64): ID of the base form of the word, with no\n",
      " |      inflectional suffixes.\n",
      " |  \n",
      " |  lemma_\n",
      " |      RETURNS (str): The token lemma, i.e. the base form of the word,\n",
      " |      with no inflectional suffixes.\n",
      " |  \n",
      " |  lex\n",
      " |      RETURNS (Lexeme): The underlying lexeme.\n",
      " |  \n",
      " |  lex_id\n",
      " |      RETURNS (int): Sequential ID of the token's lexical type.\n",
      " |  \n",
      " |  like_email\n",
      " |      RETURNS (bool): Whether the token resembles an email address.\n",
      " |  \n",
      " |  like_num\n",
      " |      RETURNS (bool): Whether the token resembles a number, e.g. \"10.9\",\n",
      " |      \"10\", \"ten\", etc.\n",
      " |  \n",
      " |  like_url\n",
      " |      RETURNS (bool): Whether the token resembles a URL.\n",
      " |  \n",
      " |  lower\n",
      " |      RETURNS (uint64): ID of the lowercase token text.\n",
      " |  \n",
      " |  lower_\n",
      " |      RETURNS (str): The lowercase token text. Equivalent to\n",
      " |      `Token.text.lower()`.\n",
      " |  \n",
      " |  morph\n",
      " |  \n",
      " |  n_lefts\n",
      " |      The number of leftward immediate children of the word, in the\n",
      " |      syntactic dependency parse.\n",
      " |      \n",
      " |      RETURNS (int): The number of leftward immediate children of the\n",
      " |          word, in the syntactic dependency parse.\n",
      " |      \n",
      " |      DOCS: https://spacy.io/api/token#n_lefts\n",
      " |  \n",
      " |  n_rights\n",
      " |      The number of rightward immediate children of the word, in the\n",
      " |      syntactic dependency parse.\n",
      " |      \n",
      " |      RETURNS (int): The number of rightward immediate children of the\n",
      " |          word, in the syntactic dependency parse.\n",
      " |      \n",
      " |      DOCS: https://spacy.io/api/token#n_rights\n",
      " |  \n",
      " |  norm\n",
      " |      RETURNS (uint64): ID of the token's norm, i.e. a normalised form of\n",
      " |      the token text. Usually set in the language's tokenizer exceptions\n",
      " |      or norm exceptions.\n",
      " |  \n",
      " |  norm_\n",
      " |      RETURNS (str): The token's norm, i.e. a normalised form of the\n",
      " |      token text. Usually set in the language's tokenizer exceptions or\n",
      " |      norm exceptions.\n",
      " |  \n",
      " |  orth\n",
      " |      RETURNS (uint64): ID of the verbatim text content.\n",
      " |  \n",
      " |  orth_\n",
      " |      RETURNS (str): Verbatim text content (identical to\n",
      " |      `Token.text`). Exists mostly for consistency with the other\n",
      " |      attributes.\n",
      " |  \n",
      " |  pos\n",
      " |      RETURNS (uint64): ID of coarse-grained part-of-speech tag.\n",
      " |  \n",
      " |  pos_\n",
      " |      RETURNS (str): Coarse-grained part-of-speech tag.\n",
      " |  \n",
      " |  prefix\n",
      " |      RETURNS (uint64): ID of a length-N substring from the start of the\n",
      " |      token. Defaults to `N=1`.\n",
      " |  \n",
      " |  prefix_\n",
      " |      RETURNS (str): A length-N substring from the start of the token.\n",
      " |      Defaults to `N=1`.\n",
      " |  \n",
      " |  prob\n",
      " |      RETURNS (float): Smoothed log probability estimate of token type.\n",
      " |  \n",
      " |  rank\n",
      " |      RETURNS (int): Sequential ID of the token's lexical type, used to\n",
      " |      index into tables, e.g. for word vectors.\n",
      " |  \n",
      " |  right_edge\n",
      " |      The rightmost token of this token's syntactic descendents.\n",
      " |      \n",
      " |      RETURNS (Token): The last token such that `self.is_ancestor(token)`.\n",
      " |  \n",
      " |  rights\n",
      " |      The rightward immediate children of the word, in the syntactic\n",
      " |      dependency parse.\n",
      " |      \n",
      " |      YIELDS (Token): A right-child of the token.\n",
      " |      \n",
      " |      DOCS: https://spacy.io/api/token#rights\n",
      " |  \n",
      " |  sent\n",
      " |      RETURNS (Span): The sentence span that the token is a part of.\n",
      " |  \n",
      " |  sent_start\n",
      " |  \n",
      " |  sentiment\n",
      " |      RETURNS (float): A scalar value indicating the positivity or\n",
      " |      negativity of the token.\n",
      " |  \n",
      " |  shape\n",
      " |      RETURNS (uint64): ID of the token's shape, a transform of the\n",
      " |      token's string, to show orthographic features (e.g. \"Xxxx\", \"dd\").\n",
      " |  \n",
      " |  shape_\n",
      " |      RETURNS (str): Transform of the token's string, to show\n",
      " |      orthographic features. For example, \"Xxxx\" or \"dd\".\n",
      " |  \n",
      " |  subtree\n",
      " |      A sequence containing the token and all the token's syntactic\n",
      " |      descendants.\n",
      " |      \n",
      " |      YIELDS (Token): A descendent token such that\n",
      " |          `self.is_ancestor(descendent) or token == self`.\n",
      " |      \n",
      " |      DOCS: https://spacy.io/api/token#subtree\n",
      " |  \n",
      " |  suffix\n",
      " |      RETURNS (uint64): ID of a length-N substring from the end of the\n",
      " |      token. Defaults to `N=3`.\n",
      " |  \n",
      " |  suffix_\n",
      " |      RETURNS (str): A length-N substring from the end of the token.\n",
      " |      Defaults to `N=3`.\n",
      " |  \n",
      " |  tag\n",
      " |      RETURNS (uint64): ID of fine-grained part-of-speech tag.\n",
      " |  \n",
      " |  tag_\n",
      " |      RETURNS (str): Fine-grained part-of-speech tag.\n",
      " |  \n",
      " |  tensor\n",
      " |  \n",
      " |  text\n",
      " |      RETURNS (str): The original verbatim text of the token.\n",
      " |  \n",
      " |  text_with_ws\n",
      " |      RETURNS (str): The text content of the span (with trailing\n",
      " |      whitespace).\n",
      " |  \n",
      " |  vector\n",
      " |      A real-valued meaning representation.\n",
      " |      \n",
      " |      RETURNS (numpy.ndarray[ndim=1, dtype='float32']): A 1D numpy array\n",
      " |          representing the token's semantics.\n",
      " |      \n",
      " |      DOCS: https://spacy.io/api/token#vector\n",
      " |  \n",
      " |  vector_norm\n",
      " |      The L2 norm of the token's vector representation.\n",
      " |      \n",
      " |      RETURNS (float): The L2 norm of the vector representation.\n",
      " |      \n",
      " |      DOCS: https://spacy.io/api/token#vector_norm\n",
      " |  \n",
      " |  vocab\n",
      " |  \n",
      " |  whitespace_\n",
      " |      RETURNS (str): The trailing whitespace character, if present.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __pyx_vtable__ = <capsule object NULL>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(spacy.tokens.token.Token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "044494d3",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_38854/194655414.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"I like New York in Autumn.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mrights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdoc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlefts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0mrights\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"in\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "doc = nlp(\"I like New York in Autumn.\")\n",
    "rights = [t.text for t in doc[1].lefts]\n",
    "assert rights == [\"in\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "75a0ea0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f006ec7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New York York like\n",
      "Autumn Autumn in\n"
     ]
    }
   ],
   "source": [
    "for e in doc.ents:\n",
    "    print(e, e.root, e.root.head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "98a5083a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " I like\n",
      "\n",
      " like like\n",
      "I\n",
      "York\n",
      ".\n",
      "I\n",
      "\n",
      " New York\n",
      "\n",
      " York like\n",
      "New\n",
      "in\n",
      "New\n",
      "\n",
      " in York\n",
      "Autumn\n",
      "\n",
      " Autumn in\n",
      "\n",
      " . like\n"
     ]
    }
   ],
   "source": [
    "for t in doc:\n",
    "    print(\"\\n\",t, t.head)\n",
    "    for child in t.children:\n",
    "        print(child)\n",
    "    for left in t.lefts:\n",
    "        print(left)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b66ea93e",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_pass = nlp(\"I have been married to my wife for 30 years\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "be1c4642",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I nsubj\n",
      "have aux\n",
      "been ROOT\n",
      "married acomp\n",
      "to prep\n",
      "my poss\n",
      "wife pobj\n",
      "for prep\n",
      "30 nummod\n",
      "years pobj\n"
     ]
    }
   ],
   "source": [
    "for t in doc_pass:\n",
    "    print(t,t.dep_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "623fbcdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_2verbs = nlp(\"Apple is looking at buying Amazon for $1 billion\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "7ffbc3a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found token:  buying\n",
      "passive:  False\n",
      "subject:  Apple\n",
      "right:  Amazon\n",
      "object:  Amazon\n",
      "(('Apple', 'ORG'), 'buy', ('Amazon', 'ORG'))\n"
     ]
    }
   ],
   "source": [
    "for elem in extract_rel_dep(doc_2verbs, pred_name=\"buy\",pred_synonyms=[\"buy\"]):\n",
    "    print(elem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "8258cdd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOKEN:  Apple \n",
      "depencies: nsubj \n",
      "token's head: looking\n",
      "TOKEN:  is \n",
      "depencies: aux \n",
      "token's head: looking\n",
      "TOKEN:  looking \n",
      "depencies: ROOT \n",
      "token's head: looking\n",
      "children: \n",
      " Apple\n",
      "children: \n",
      " is\n",
      "children: \n",
      " at\n",
      "lefts: \n",
      " Apple\n",
      "lefts: \n",
      " is\n",
      "rights: \n",
      " at\n",
      "TOKEN:  at \n",
      "depencies: prep \n",
      "token's head: looking\n",
      "children: \n",
      " buying\n",
      "rights: \n",
      " buying\n",
      "TOKEN:  buying \n",
      "depencies: pcomp \n",
      "token's head: at\n",
      "children: \n",
      " startup\n",
      "children: \n",
      " for\n",
      "rights: \n",
      " startup\n",
      "rights: \n",
      " for\n",
      "TOKEN:  U.K. \n",
      "depencies: compound \n",
      "token's head: startup\n",
      "TOKEN:  startup \n",
      "depencies: dobj \n",
      "token's head: buying\n",
      "children: \n",
      " U.K.\n",
      "lefts: \n",
      " U.K.\n",
      "TOKEN:  for \n",
      "depencies: prep \n",
      "token's head: buying\n",
      "children: \n",
      " billion\n",
      "rights: \n",
      " billion\n",
      "TOKEN:  $ \n",
      "depencies: quantmod \n",
      "token's head: billion\n",
      "TOKEN:  1 \n",
      "depencies: compound \n",
      "token's head: billion\n",
      "TOKEN:  billion \n",
      "depencies: pobj \n",
      "token's head: for\n",
      "children: \n",
      " $\n",
      "children: \n",
      " 1\n",
      "lefts: \n",
      " $\n",
      "lefts: \n",
      " 1\n"
     ]
    }
   ],
   "source": [
    "for t in doc_2verbs:\n",
    "    print(\"TOKEN: \",t,\"\\ndepencies:\",t.dep_,\"\\ntoken's head:\", t.head)\n",
    "    for child in t.children:\n",
    "        print(\"children: \\n\",child)\n",
    "    for left in t.lefts:\n",
    "        print(\"lefts: \\n\",left)\n",
    "    for right in t.rights:\n",
    "        print(\"rights: \\n\",right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7f7ae361",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_verb_before = nlp(\"If I eat an apple, I drink water\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "ac61065f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spacy.tokens.doc.Doc"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(doc_verb_before)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0d7a3ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def peek(iterable):\n",
    "    try:\n",
    "        first = next(iterable)\n",
    "    except StopIteration:\n",
    "        return None\n",
    "    return iterable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6acb2ba2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOKEN:  If \n",
      "token's head: eat\n",
      "\n",
      "\n",
      "TOKEN:  I \n",
      "token's head: eat\n",
      "\n",
      "\n",
      "TOKEN:  eat \n",
      "token's head: drink\n",
      "Children:\n",
      "If\n",
      "I\n",
      "apple\n",
      "Lefts:\n",
      "If\n",
      "I\n",
      "Rights:\n",
      "apple\n",
      "\n",
      "\n",
      "TOKEN:  an \n",
      "token's head: apple\n",
      "\n",
      "\n",
      "TOKEN:  apple \n",
      "token's head: eat\n",
      "Children:\n",
      "an\n",
      "Lefts:\n",
      "an\n",
      "\n",
      "\n",
      "TOKEN:  , \n",
      "token's head: drink\n",
      "\n",
      "\n",
      "TOKEN:  I \n",
      "token's head: drink\n",
      "\n",
      "\n",
      "TOKEN:  drink \n",
      "token's head: drink\n",
      "Children:\n",
      "eat\n",
      ",\n",
      "I\n",
      "water\n",
      "Lefts:\n",
      "eat\n",
      ",\n",
      "I\n",
      "Rights:\n",
      "water\n",
      "\n",
      "\n",
      "TOKEN:  water \n",
      "token's head: drink\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for t in doc_verb_before:\n",
    "    print(\"TOKEN: \",t,\"\\ntoken's head:\", t.head)\n",
    "    if peek(t.children):\n",
    "        print(\"Children:\")\n",
    "        for child in t.children:\n",
    "            print(child)\n",
    "    if peek(t.lefts):\n",
    "        print(\"Lefts:\")\n",
    "        for left in t.lefts:\n",
    "            print(left)\n",
    "    if peek(t.rights):\n",
    "        print(\"Rights:\")\n",
    "        for right in t.rights:\n",
    "            print(right)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d55c17a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "If"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(doc_verb_before[2].children)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f60ba98d",
   "metadata": {},
   "source": [
    "Back to the [table of contents](#contents).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "fbd6fc6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "reuters_fileids_crude = reuters.fileids(categories=['crude'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "5c7d981a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'test/16658'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reuters_fileids_crude[25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "3bb072c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "article = reuters.raw(reuters_fileids_crude[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "41c2e053",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ENERGY/U.S. PETROCHEMICAL INDUSTRY Cheap oil feedstocks, the weakened U.S. dollar and a plant utilization rate approaching 90 pct will propel the streamlined U.S. petrochemical industry to record profits this year, with growth expected through at least 1990, major company executives predicted. This bullish outlook for chemical manufacturing and an industrywide move to shed unrelated businesses has prompted GAF Corp &lt;GAF>, privately-held Cain Chemical Inc, and other firms to aggressively seek acquisitions of petrochemical plants. Oil companies such as Ashland Oil Inc &lt;ASH>, the Kentucky-based oil refiner and marketer, are also shopping for money-making petrochemical businesses to buy. \"I see us poised at the threshold of a golden period,\" said Paul Oreffice, chairman of giant Dow Chemical Co &lt;DOW>, adding, \"Ther\\'s no major plant capacity being added around the world now. The whole game is bringing out new products and improving the old ones.\" Analysts say the chemical industr\\'s biggest customers, automobile manufacturers and home builders that use a lot of paints and plastics, are expected to buy quantities this year. U.S. petrochemical plants are currently operating at about 90 pct capacity, reflecting tighter supply that could hike product prices by 30 to 40 pct this year, said John Dosher, managing director of Pace Consultants Inc of Houston. Demand for some products such as styrene could push profit margins up by as much as 300 pct, he said. Oreffice, speaking at a meeting of chemical engineers in Houston, said Dow would easily top the 741 mln dlrs it earned last year and predicted it would have the best year in its history. In 1985, when oil prices were still above 25 dlrs a barrel and chemical exports were adversely affected by the strong U.S. dollar, Dow had profits of 58 mln dlrs. \"I believe the entire chemical industry is headed for a record year or close to it,\" Oreffice said. GAF chairman Samuel Heyman estimated that the U.S. chemical industry would report a 20 pct gain in profits during 1987. Last year, the domestic industry earned a total of 13 billion dlrs, a 54 pct leap from 1985. The turn in the fortunes of the once-sickly chemical industry has been brought about by a combination of luck and planning, said Pac\\'s John Dosher. Dosher said last yea\\'s fall in oil prices made feedstocks dramatically cheaper and at the same time the American dollar was weakening against foreign currencies. That helped boost U.S. chemical exports. Also helping to bring supply and demand into balance has been the gradual market absorption of the extra chemical manufacturing capacity created by Middle Eastern oil producers in the early 1980s. Finally, virtually all major U.S. chemical manufacturers have embarked on an extensive corporate restructuring program to mothball inefficient plants, trim the payroll and eliminate unrelated businesses. The restructuring touched off a flurry of friendly and hostile takeover attempts. GAF, which made an unsuccessful attempt in 1985 to acquire Union Carbide Corp &lt;UK>, recently offered three billion dlrs for Borg Warner Corp &lt;BOR>, a Chicago manufacturer of plastics and chemicals. Another industry powerhouse, W.R. Grace &lt;GRA> has divested its retailing, restaurant and fertilizer businesses to raise cash for chemical acquisitions. But some experts worry that the chemical industry may be headed for trouble if companies continue turning their back on the manufacturing of staple petrochemical commodities, such as ethylene, in favor of more profitable specialty chemicals that are custom-designed for a small group of buyers. \"Companies like DuPont &lt;DD> and Monsanto Co &lt;MTC> spent the past two or three years trying to get out of the commodity chemical business in reaction to how badly the market had deteriorated,\" Dosher said. \"But I think they will eventually kill the margins on the profitable chemicals in the niche market.\" Some top chemical executives share the concern. \"The challenge for our industry is to keep from getting carried away and repeating past mistakes,\" GA\\'s Heyman cautioned. \"The shift from commodity chemicals may be ill-advised. Specialty businesses do not stay special long.\" Houston-based Cain Chemical, created this month by the Sterling investment banking group, believes it can generate 700 mln dlrs in annual sales by bucking the industry trend. Chairman Gordon Cain, who previously led a leveraged buyout of Dupon\\'s Conoco In\\'s chemical business, has spent 1.1 billion dlrs since January to buy seven petrochemical plants along the Texas Gulf Coast. The plants produce only basic commodity petrochemicals that are the building blocks of specialty products. \"This kind of commodity chemical business will never be a glamorous, high-margin business,\" Cain said, adding that demand is expected to grow by about three pct annually. Garo Armen, an analyst with Dean Witter Reynolds, said chemical makers have also benefitted by increasing demand for plastics as prices become more competitive with aluminum, wood and steel products. Armen estimated the upturn in the chemical business could last as long as four or five years, provided the U.S. economy continues its modest rate of growth.'"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pattern = re.compile(\"\\n\")\n",
    "article = re.sub(pattern,\"\",article)\n",
    "pattern = re.compile(\" +\")\n",
    "article = re.sub(pattern,\" \",article)\n",
    "pattern = re.compile(\".'s\")\n",
    "article = re.sub(pattern,\"'s\",article) #???\n",
    "article = article.strip()\n",
    "#re.findall(\"(\\w[^\\.]*\\.)\",article)\n",
    "article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "292f8cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_reuters = nlp(article)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "4e440c0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25 dlrs\n"
     ]
    }
   ],
   "source": [
    "for ent in doc_reuters.ents:\n",
    "    if ent.label_ == \"QUANTITY\":\n",
    "        print(ent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "07dcc34d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ENERGY/U.S. PETROCHEMICAL INDUSTRY\\n  Cheap oil feedstocks, the weakened U.S.\\n  dollar and a plant utilization rate approaching 90 pct will\\n  propel the streamlined U.S. petrochemical industry to record\\n  profits this year, with growth expected through at least 1990,\\n  major company executives predicted.\\n      This bullish outlook for chemical manufacturing and an\\n  industrywide move to shed unrelated businesses has prompted GAF\\n  Corp &lt;GAF>, privately-held Cain Chemical Inc, and other firms\\n  to aggressively seek acquisitions of petrochemical plants.\\n      Oil companies such as Ashland Oil Inc &lt;ASH>, the\\n  Kentucky-based oil refiner and marketer, are also shopping for\\n  money-making petrochemical businesses to buy.\\n      \"I see us poised at the threshold of a golden period,\" said\\n  Paul Oreffice, chairman of giant Dow Chemical Co &lt;DOW>, adding,\\n  \"There\\'s no major plant capacity being added around the world\\n  now. The whole game is bringing out new products and improving\\n  the old ones.\"\\n      Analysts say the chemical industry\\'s biggest customers,\\n  automobile manufacturers and home builders that use a lot of\\n  paints and plastics, are expected to buy quantities this year.\\n      U.S. petrochemical plants are currently operating at about\\n  90 pct capacity, reflecting tighter supply that could hike\\n  product prices by 30 to 40 pct this year, said John Dosher,\\n  managing director of Pace Consultants Inc of Houston. Demand\\n  for some products such as styrene could push profit margins up\\n  by as much as 300 pct, he said.\\n      Oreffice, speaking at a meeting of chemical engineers in\\n  Houston, said Dow would easily top the 741 mln dlrs it earned\\n  last year and predicted it would have the best year in its\\n  history.\\n      In 1985, when oil prices were still above 25 dlrs a barrel\\n  and chemical exports were adversely affected by the strong U.S.\\n  dollar, Dow had profits of 58 mln dlrs. \"I believe the entire\\n  chemical industry is headed for a record year or close to it,\"\\n  Oreffice said.\\n      GAF chairman Samuel Heyman estimated that the U.S. chemical\\n  industry would report a 20 pct gain in profits during 1987.\\n  Last year, the domestic industry earned a total of 13 billion\\n  dlrs, a 54 pct leap from 1985.\\n      The turn in the fortunes of the once-sickly chemical\\n  industry has been brought about by a combination of luck and\\n  planning, said Pace\\'s John Dosher.\\n      Dosher said last year\\'s fall in oil prices made feedstocks\\n  dramatically cheaper and at the same time the American dollar\\n  was weakening against foreign currencies. That helped boost\\n  U.S. chemical exports.\\n      Also helping to bring supply and demand into balance has\\n  been the gradual market absorption of the extra chemical\\n  manufacturing capacity created by Middle Eastern oil producers\\n  in the early 1980s.\\n      Finally, virtually all major U.S. chemical manufacturers\\n  have embarked on an extensive corporate restructuring program\\n  to mothball inefficient plants, trim the payroll and eliminate\\n  unrelated businesses. The restructuring touched off a flurry of\\n  friendly and hostile takeover attempts.\\n      GAF, which made an unsuccessful attempt in 1985 to acquire\\n  Union Carbide Corp &lt;UK>, recently offered three billion dlrs\\n  for Borg Warner Corp &lt;BOR>, a Chicago manufacturer of plastics\\n  and chemicals. Another industry powerhouse, W.R. Grace &lt;GRA> \\n  has divested its retailing, restaurant and fertilizer\\n  businesses to raise cash for chemical acquisitions.\\n      But some experts worry that the chemical industry may be\\n  headed for trouble if companies continue turning their back on\\n  the manufacturing of staple petrochemical commodities, such as\\n  ethylene, in favor of more profitable specialty chemicals that\\n  are custom-designed for a small group of buyers.\\n      \"Companies like DuPont &lt;DD> and Monsanto Co &lt;MTC> spent the\\n  past two or three years trying to get out of the commodity\\n  chemical business in reaction to how badly the market had\\n  deteriorated,\" Dosher said. \"But I think they will eventually\\n  kill the margins on the profitable chemicals in the niche\\n  market.\" Some top chemical executives share the concern.\\n      \"The challenge for our industry is to keep from getting\\n  carried away and repeating past mistakes,\" GAF\\'s Heyman\\n  cautioned. \"The shift from commodity chemicals may be\\n  ill-advised. Specialty businesses do not stay special long.\"\\n      Houston-based Cain Chemical, created this month by the\\n  Sterling investment banking group, believes it can generate 700\\n  mln dlrs in annual sales by bucking the industry trend.\\n      Chairman Gordon Cain, who previously led a leveraged buyout\\n  of Dupont\\'s Conoco Inc\\'s chemical business, has spent 1.1\\n  billion dlrs since January to buy seven petrochemical plants\\n  along the Texas Gulf Coast.\\n      The plants produce only basic commodity petrochemicals that\\n  are the building blocks of specialty products.\\n      \"This kind of commodity chemical business will never be a\\n  glamorous, high-margin business,\" Cain said, adding that demand\\n  is expected to grow by about three pct annually.\\n      Garo Armen, an analyst with Dean Witter Reynolds, said\\n  chemical makers have also benefitted by increasing demand for\\n  plastics as prices become more competitive with aluminum, wood\\n  and steel products. Armen estimated the upturn in the chemical\\n  business could last as long as four or five years, provided the\\n  U.S. economy continues its modest rate of growth.\\n  \\n\\n'"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reuters.raw(reuters_fileids_crude[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "98478166",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'TURKEY CALLS FOR DIALOGUE TO SOLVE DISPUTE\\n  Turkey said today its disputes with\\n  Greece, including rights on the continental shelf in the Aegean\\n  Sea, should be solved through negotiations.\\n      A Foreign Ministry statement said the latest crisis between\\n  the two NATO members stemmed from the continental shelf dispute\\n  and an agreement on this issue would effect the security,\\n  economy and other rights of both countries.\\n      \"As the issue is basicly political, a solution can only be\\n  found by bilateral negotiations,\" the statement said. Greece has\\n  repeatedly said the issue was legal and could be solved at the\\n  International Court of Justice.\\n      The two countries approached armed confrontation last month\\n  after Greece announced it planned oil exploration work in the\\n  Aegean and Turkey said it would also search for oil.\\n      A face-off was averted when Turkey confined its research to\\n  territorrial waters. \"The latest crises created an historic\\n  opportunity to solve the disputes between the two countries,\"\\n  the Foreign Ministry statement said.\\n      Turkey\\'s ambassador in Athens, Nazmi Akiman, was due to\\n  meet Prime Minister Andreas Papandreou today for the Greek\\n  reply to a message sent last week by Turkish Prime Minister\\n  Turgut Ozal. The contents of the message were not disclosed.\\n  \\n\\n'"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reuters.raw(reuters_fileids_crude[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec1f67df",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"nummod\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Algorythm",
   "language": "python",
   "name": "algorythm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
